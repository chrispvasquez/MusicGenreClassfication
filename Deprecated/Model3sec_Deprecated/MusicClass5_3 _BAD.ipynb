{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from keras import layers\n",
    "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \n",
    "                          Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D)\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "import pydot\n",
    "from IPython.display import SVG, Audio\n",
    "from keras.layers import Dropout, GlobalAveragePooling2D\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix\n",
    "from HelperFunctions import *\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'\n",
    "genres = genres.split()\n",
    "\n",
    "directory = \"content/spectrograms3sec/train/\"\n",
    "for g in genres:\n",
    "  if len(os.listdir(os.path.join('content/spectrograms3sec/test/',f\"{g}\"))) == 0:\n",
    "    filenames = os.listdir(os.path.join(directory,f\"{g}\"))\n",
    "    random.shuffle(filenames)\n",
    "    test_files = filenames[0:200]\n",
    "\n",
    "    for f in test_files:\n",
    "\n",
    "      shutil.move(directory + f\"{g}\"+ \"/\" + f,\"content/spectrograms3sec/test/\" + f\"{g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"content/spectrograms3sec/train/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(128,128),color_mode=\"rgba\",class_mode='categorical',batch_size=64)\n",
    "\n",
    "validation_dir = \"content/spectrograms3sec/test/\"\n",
    "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
    "vali_generator = vali_datagen.flow_from_directory(validation_dir,target_size=(128,128),color_mode='rgba',class_mode='categorical',batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenreModel(input_shape = (128,128, 4),classes=10):\n",
    "  X_input = Input(input_shape)\n",
    "\n",
    "  X = Conv2D(32, kernel_size=(3,3))(X_input)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  X = Dropout(rate=0.3)(X)\n",
    "\n",
    "  X = Conv2D(64, kernel_size=(3,3))(X_input)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  X = Dropout(rate=0.3)(X)\n",
    "\n",
    "  X = Conv2D(128, kernel_size=(3,3))(X_input)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  X = Dropout(rate=0.3)(X)\n",
    "\n",
    "  X = Flatten()(X)\n",
    "\n",
    "  X = Dense(classes)(X)\n",
    "\n",
    "  X = Dropout(rate=0.3)(X)\n",
    "\n",
    "  X = Dense(classes, activation='softmax')(X)\n",
    "\n",
    "\n",
    "  model = Model(inputs=X_input,outputs=X,name='GenreModel')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"saved_cnn3/cp.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                 save_weights_only=False,\n",
    "#                                                 verbose=1)\n",
    "\n",
    "model = GenreModel(input_shape=(128,128, 4), classes=10)\n",
    "opt = Adadelta()\n",
    "model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67/141 [=============>................] - ETA: 15s - loss: 2.0132 - accuracy: 0.2768"
     ]
    }
   ],
   "source": [
    "fresh_model = True\n",
    "\n",
    "if os.path.exists(\"saved/saved_cnn5_3\"):\n",
    "    model_history = keras.models.load_model(\"saved/saved_cnn5_3\")\n",
    "else:\n",
    "    model_history = model.fit(train_generator,epochs=80,validation_data=vali_generator)\n",
    "    model.save(\"saved/saved_cnn5_3\")\n",
    "    fresh_model = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fresh_model:\n",
    "    metrics = model_history.history\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(model_history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.ylim([0, max(plt.ylim())])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(model_history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "    plt.legend(['accuracy', 'val_accuracy'])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(vali_generator, batch_size=128)\n",
    "print(\"The test Loss is :\", test_loss)\n",
    "print(\"\\nThe Best test Accuracy is :\", test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class estimator:\n",
    "  _estimator_type = ''\n",
    "  classes_=[]\n",
    "  def __init__(self, model, classes):\n",
    "    self.model = model\n",
    "    self._estimator_type = 'classifier'\n",
    "    self.classes_ = classes\n",
    "  def predict(self, X):\n",
    "    y_prob= self.model.predict(X)\n",
    "    y_pred = y_prob.argmax(axis=1)\n",
    "    return y_pred\n",
    "\n",
    "classifier = estimator(model, genres)\n",
    "figsize = (12,12)\n",
    "\n",
    "x, y = zip(*(vali_generator[i] for i in range(len(vali_generator))))\n",
    "x_val, y_val = np.vstack(x), np.vstack(y)\n",
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(classifier, x_val, y_val, cmap='Blues', display_labels=genres ,normalize='true', ax=plt.subplots(figsize=figsize)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "input_dir = pathlib.Path(\"input/\")\n",
    "audio_file_name = \"chopin.wav\"\n",
    "sample_dir = \"input/samples/\"\n",
    "audio_seg_dir = \"input/audio_segments/\"\n",
    "spec_dir = \"input/mfccs_segments/\"\n",
    "\n",
    "if not input_dir.exists():\n",
    "    os.mkdir(\"input\")\n",
    "    os.mkdir(sample_dir)\n",
    "    os.mkdir(audio_seg_dir)\n",
    "\n",
    "sample, sample_sr = librosa.load(os.path.join(sample_dir, audio_file_name))\n",
    "sample_duration = int(librosa.get_duration(y=sample, sr=sample_sr))\n",
    "Audio(sample, rate=sample_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chopAudio(os.path.join(sample_dir, audio_file_name), audio_seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiosToGraph(audio_seg_dir, spec_dir,type=\"mfcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for af in os.listdir(spec_dir):\n",
    "    image_data = load_img(os.path.join(spec_dir, af[:-3] + 'png'),color_mode='rgba',target_size=(26,65))\n",
    "    image = img_to_array(image_data)\n",
    "    image = np.reshape(image,(1,26,65,4))\n",
    "\n",
    "    p = model.predict(image/255)\n",
    "    p = p.reshape((10,))\n",
    "\n",
    "    predictions.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = [x / len(predictions) for x in np.array(predictions).sum(axis=0)]\n",
    "predicted_label = np.argmax(avg_preds)\n",
    "\n",
    "print(\"The Predicted Label was: \" + genres[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.bar(genres, np.array(avg_preds))\n",
    "plt.title(\"Inference Results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4bb7afac8597c20637caf6f54724b14b6cf9e4d56fd32da9d2b0cee309b1256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
